{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2d9850",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingenier√≠a - Computaci√≥n</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -10px\">\n",
    "        <strong>Curso:</strong> Responsible AI\n",
    "        <strong>Secci√≥n:</strong> 10\n",
    "        <strong>Repositorio:</strong> https://github.com/Dahernandezsilve/ResponsibleAI-Realworld-Data-Scraper\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Proyecto:</strong> Preprocesamiento de Datos</p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autores:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hern√°ndez Silvestre - <strong>21270</strong></li>\n",
    "        <li>Linda In√©s Jim√©nez Vides - <strong>21169</strong></li>\n",
    "        <li>Mario Antonio Guerra Morales - <strong>21008</strong></li>\n",
    "        <li>Daniel Adolfo Sarmiento Peralta - <strong>231105</strong></li>\n",
    "        <li>Kristopher Javier Alvarado L√≥pez - <strong>21188</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58071cd8",
   "metadata": {},
   "source": [
    "# üßº Preprocesamiento ‚Äî flujo √∫nico y reproducible\n",
    "\n",
    "**Entradas:**  `data.json`  \n",
    "**Salidas:**  \n",
    "- `clean_data.parquet` *(o `clean_data.csv` si Parquet no est√° disponible)*  \n",
    "- `profiling.md` *(resumen NA y describe num√©rico)*  \n",
    "\n",
    "---\n",
    "Este flujo unifica:\n",
    "- Limpieza b√°sica y normalizaci√≥n de direcciones (incluye Carretera a El Salvador y mapa de ciudades)\n",
    "- Normalizaci√≥n de moneda y precios\n",
    "- Tratamiento de nulos, outliers y zonas\n",
    "- Generaci√≥n de m√©tricas de diagn√≥stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d592a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc589571",
   "metadata": {},
   "source": [
    "## üìÅ Par√°metros iniciales y configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7827fef8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Rutas y par√°metros\n",
    "data_path: str = \"data.json\"\n",
    "id_col: str = \"id\"\n",
    "null_col_threshold: float = 0.95      # columnas con >95% nulos se eliminan\n",
    "outlier_quantile: float = 0.99        # p99 para filtrar outliers\n",
    "date_cols = [\"created_at\", \"updated_at\"]\n",
    "\n",
    "# Columnas t√©cnicas / baja utilidad de negocio (se podan al inicio)\n",
    "cols_drop_tech = [\n",
    "    \"price_change\",\n",
    "    \"translated_title\",\n",
    "    \"completed_step\",\n",
    "    \"steps\",\n",
    "    \"fts\",\n",
    "    \"storage_path\",\n",
    "    \"storage_path_original\",\n",
    "    \"property_order\",\n",
    "    \"storage_path_resize\",\n",
    "]\n",
    "\n",
    "# Columnas espec√≠ficas poco √∫tiles para an√°lisis\n",
    "cols_drop_specific = [\"slug\", \"zip\", \"logo\", \"coordinates\"]\n",
    "\n",
    "# Tasas de cambio (nota: si el per√≠odo es largo, esto fija una foto en el tiempo)\n",
    "conversion_rates: Dict[Optional[str], float] = {\n",
    "    \"USD\": 7.82,\n",
    "    \"GTQ\": 1.00,\n",
    "    \"MXN\": 0.45,\n",
    "    \"DOP\": 0.13,\n",
    "    None: 1.00,\n",
    "}\n",
    "\n",
    "def log(msg: str) -> None:\n",
    "    \"\"\"Imprime log con timestamp.\"\"\"\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a73a04",
   "metadata": {},
   "source": [
    "## üîß Utilidades de texto y helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35e3070a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def strip_accents(s: str) -> str:\n",
    "    \"\"\"Quita tildes/diacr√≠ticos usando stdlib (sin dependencias).\"\"\"\n",
    "    return \"\".join(\n",
    "        ch for ch in unicodedata.normalize(\"NFD\", s)\n",
    "        if unicodedata.category(ch) != \"Mn\"\n",
    "    )\n",
    "\n",
    "def collapse_spaces(s: str) -> str:\n",
    "    \"\"\"Colapsa espacios m√∫ltiples y recorta.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def clean_basic(value):\n",
    "    \"\"\"\n",
    "    Min√∫sculas + quita comillas dobles + colapso de espacios.\n",
    "    *No* remueve acentos (para preservar nombres oficiales), eso se hace solo cuando se busca en el map.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    s = str(value).strip().lower()\n",
    "    s = s.replace('\"', \"\")             # quita comillas dobles\n",
    "    s = collapse_spaces(s)\n",
    "    return s\n",
    "\n",
    "def pct(x: float) -> str:\n",
    "    \"\"\"Formato porcentaje corto.\"\"\"\n",
    "    return f\"{100*x:.1f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb8313",
   "metadata": {},
   "source": [
    "## üåÜ Normalizaci√≥n de ciudades (city_replace_map)\n",
    "Map de errores comunes ‚Üí forma oficial (con tildes correctas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0018b4fa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "city_replace_map = {\n",
    "    \"guatemala city\": \"ciudad de guatemala\",\n",
    "    \"guatemala\": \"ciudad de guatemala\",\n",
    "    \"guatemala \": \"ciudad de guatemala\",\n",
    "    \"ciudad guatemala\": \"ciudad de guatemala\",\n",
    "    \"ciudad de gutemala\": \"ciudad de guatemala\",\n",
    "    \"ciudad de guatemala \": \"ciudad de guatemala\",\n",
    "    \"ciudad de panama\": \"panama\",\n",
    "    \"guazacapan\": \"guazacap√°n\",\n",
    "    \"esquintla\": \"escuintla\",\n",
    "    \"san jose\": \"san jos√©\",\n",
    "    \"palin\": \"pal√≠n\",\n",
    "    \"san miguel duenas\": \"san miguel due√±as\",\n",
    "    \"san lucas sacatepequez\": \"san lucas sacatep√©quez\",\n",
    "    \"suchitepequez\": \"suchitep√©quez\",\n",
    "    \"sacatepequez\": \"sacatep√©quez\",\n",
    "    \"quezaltenango\": \"quetzaltenango\",\n",
    "    \"san juan sacatepequez\": \"san juan sacatep√©quez\",\n",
    "    \"mixco \": \"mixco\",\n",
    "    \"santa catarina pinula \": \"santa catarina pinula\",\n",
    "}\n",
    "\n",
    "def normalize_city(city_raw: str) -> str:\n",
    "    \"\"\"\n",
    "    1) Limpieza b√°sica (lower + espacios + sin comillas).\n",
    "    2) Clave sin acentos para buscar en map (strip_accents).\n",
    "    3) Si hay match ‚Üí devuelve valor mapeado con tildes correctas.\n",
    "       Si no hay match ‚Üí devuelve el texto limpio.\n",
    "    \"\"\"\n",
    "    if pd.isna(city_raw):\n",
    "        return None\n",
    "    s = clean_basic(city_raw)\n",
    "    key = strip_accents(s)\n",
    "    return city_replace_map.get(key, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fb637",
   "metadata": {},
   "source": [
    "## üõ£Ô∏è Normalizaci√≥n de *Carretera a El Salvador* (CES/CAES/C.A.E.S./Carr. a/Al)\n",
    "Preserva Km si aparece antes o despu√©s, y el resto del contenido de la direcci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3e8ce25",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Patrones (km antes)\n",
    "pattern_km_before = re.compile(r\"\"\"\n",
    "    (?ix)\n",
    "    \\bkm\\s*\n",
    "    (?P<km>\\d+(?:[.,]\\d+)?)\n",
    "    \\b\\s*[,;:/\\.-]*\\s*\n",
    "    (?:c\\.?\\s*a\\.?\\s*e\\.?\\s*s\\.?|caes|ces|\n",
    "       carr\\.?\\s*(?:a|al)\\s*el\\s*salvador|\n",
    "       carretera\\s*(?:a\\s*)?el\\s*salvador|\n",
    "       ruta\\s*a\\s*el\\s*salvador)\n",
    "    \\b\n",
    "\"\"\", re.VERBOSE)\n",
    "\n",
    "# Patrones (km despu√©s)\n",
    "pattern_km_after = re.compile(r\"\"\"\n",
    "    (?ix)\n",
    "    \\b(?:c\\.?\\s*a\\.?\\s*e\\.?\\s*s\\.?|caes|ces|\n",
    "       carr\\.?\\s*(?:a|al)\\s*el\\s*salvador|\n",
    "       carretera\\s*(?:a\\s*)?el\\s*salvador|\n",
    "       ruta\\s*a\\s*el\\s*salvador)\\b\n",
    "    \\s*[,;:/\\.-]*\\s*\n",
    "    km\\s*(?P<km>\\d+(?:[.,]\\d+)?)\n",
    "    \\b\n",
    "\"\"\", re.VERBOSE)\n",
    "\n",
    "# Patrones (sin km expl√≠cito)\n",
    "pattern_no_km = re.compile(r\"\"\"\n",
    "    (?ix)\n",
    "    \\b(c\\.?\\s*a\\.?\\s*e\\.?\\s*s\\.?|caes|ces|\n",
    "       carr\\.?\\s*(?:a|al)\\s*el\\s*salvador|\n",
    "       carretera\\s*(?:a\\s*)?el\\s*salvador|\n",
    "       ruta\\s*a\\s*el\\s*salvador)\\b\n",
    "\"\"\", re.VERBOSE)\n",
    "\n",
    "def _km_norm(km: str) -> str:\n",
    "    \"\"\"Normaliza decimales de km: '17,5' -> '17.5'.\"\"\"\n",
    "    return km.replace(\",\", \".\")\n",
    "\n",
    "def normalize_ces_segment(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Reemplaza s√≥lo el segmento que coincide a 'Carretera a El Salvador',\n",
    "    preservando el resto del string y el valor de Km si aparece antes o despu√©s.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Km ANTES\n",
    "    def repl_before(m):\n",
    "        km = _km_norm(m.group('km'))\n",
    "        return f\"Km {km} Carretera a El Salvador\"\n",
    "\n",
    "    new_text, _ = pattern_km_before.subn(repl_before, text)\n",
    "\n",
    "    # Km DESPU√âS\n",
    "    def repl_after(m):\n",
    "        km = _km_norm(m.group('km'))\n",
    "        return f\"Carretera a El Salvador Km {km}\"\n",
    "\n",
    "    new_text, _ = pattern_km_after.subn(repl_after, new_text)\n",
    "\n",
    "    # Sin Km\n",
    "    new_text, _ = pattern_no_km.subn(\"Carretera a El Salvador\", new_text)\n",
    "\n",
    "    # Limpieza menor de separadores duplicados: \", ,\" -> \", \", etc.\n",
    "    new_text = re.sub(r\"\\s{2,}\", \" \", new_text).strip()\n",
    "    new_text = re.sub(r\"\\s*([,;:/.-])\\s*\", r\"\\1 \", new_text)   # espaciar separadores\n",
    "    new_text = collapse_spaces(new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db8aed",
   "metadata": {},
   "source": [
    "## üìä Perfilado r√°pido y utilidades de poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65d74892",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _auto_bins_numeric(s: pd.Series) -> int:\n",
    "    \"\"\"Elige #bins autom√°ticamente (FD -> Sturges).\"\"\"\n",
    "    s = s.dropna().astype(float)\n",
    "    n = len(s)\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    # Freedman‚ÄìDiaconis: h = 2*IQR / n^(1/3); k ‚âà range / h\n",
    "    q1, q3 = np.percentile(s, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    rng = s.max() - s.min()\n",
    "    if iqr > 0 and rng > 0:\n",
    "        h = 2 * iqr / (n ** (1/3))\n",
    "        if h > 0:\n",
    "            k = int(np.ceil(rng / h))\n",
    "            if k >= 1:\n",
    "                return min(k, 200)  # techo sano\n",
    "    # Fallback: Sturges (1 + log2 n)\n",
    "    k = int(np.ceil(1 + np.log2(n)))\n",
    "    return max(1, min(k, 200))\n",
    "\n",
    "def quick_profile(df: pd.DataFrame, cols, top_n: int = 10, datetime_freq: str = \"M\"):\n",
    "    \"\"\"\n",
    "    Perfil r√°pido por columna:\n",
    "      - Booleanas: conteo True/False/NA.\n",
    "      - Num√©ricas: describe + cuantiles + bins autom√°ticos (FD/Sturges) y conteo por bin.\n",
    "      - Num√©ricas discretas (pocos √∫nicos): tabla de frecuencias en vez de bins.\n",
    "      - Datetime: rango y conteo por periodo (mes por defecto).\n",
    "      - Categ√≥ricas: nunique, top categor√≠as, cobertura.\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        print(\"-\" * 40)\n",
    "        s = df[col]\n",
    "        print(f\"=== {col} ===\")\n",
    "        print(f\"dtype: {s.dtype}\")\n",
    "        miss = s.isna().mean()\n",
    "        print(f\"missing: {s.isna().sum()} ({miss:.2%})\")\n",
    "\n",
    "        # 1) Booleanos\n",
    "        if s.dtype == bool or (pd.api.types.is_bool_dtype(s) and not pd.api.types.is_numeric_dtype(s)):\n",
    "            vc = s.value_counts(dropna=False)\n",
    "            print(\"\\n[boolean counts]\\n\", vc)\n",
    "            continue\n",
    "\n",
    "        # 2) Datetime\n",
    "        if pd.api.types.is_datetime64_any_dtype(s):\n",
    "            if s.notna().any():\n",
    "                print(f\"min: {s.min()} | max: {s.max()}\")\n",
    "                grp = s.dt.to_period(datetime_freq).value_counts().sort_index()\n",
    "                print(f\"\\n[count by period '{datetime_freq}']\\n\", grp.head(top_n))\n",
    "            continue\n",
    "\n",
    "        # 3) Num√©rica\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            s_num = pd.to_numeric(s, errors=\"coerce\")\n",
    "            nunq = s_num.nunique(dropna=True)\n",
    "\n",
    "            # Discreta (pocos √∫nicos)\n",
    "            if nunq <= 20:\n",
    "                vc = s_num.value_counts(dropna=False).sort_index()\n",
    "                print(f\"nunique: {nunq} (discreta)\")\n",
    "                print(\"\\n[value counts]\\n\", vc.head(top_n))\n",
    "                print(\"\\n[describe]\\n\", s_num.describe(percentiles=[.01,.05,.25,.5,.75,.95,.99]).to_string())\n",
    "                continue\n",
    "\n",
    "            # Continua\n",
    "            print(s_num.describe(percentiles=[.01,.05,.25,.5,.75,.95,.99]).to_string())\n",
    "            try:\n",
    "                print(\"\\n[quantiles]\\n\", s_num.quantile([.01,.05,.25,.5,.75,.95,.99]))\n",
    "            except Exception as e:\n",
    "                print(f\"\\n[quantiles] omitidos: {e}\")\n",
    "\n",
    "            k = _auto_bins_numeric(s_num)\n",
    "            binned = pd.cut(s_num, bins=k, include_lowest=True)\n",
    "            print(f\"\\n[bins = {k} (auto)]\\n\", binned.value_counts().head(top_n))\n",
    "            continue\n",
    "\n",
    "        # 4) Categ√≥rica / texto\n",
    "        nunq = s.nunique(dropna=True)\n",
    "        print(f\"nunique: {nunq}\")\n",
    "        vc = s.value_counts(dropna=False).head(top_n)\n",
    "        coverage = vc.sum() / len(s)\n",
    "        print(\"[top categor√≠as]\", vc)\n",
    "        print(f\"coverage top {top_n}: {coverage:.2%}\")\n",
    "\n",
    "def drop_by_prefixes(df_in: pd.DataFrame, prefixes) -> pd.DataFrame:\n",
    "    \"\"\"Elimina columnas ra√≠z y sus anidados (p.ej. 'storage_path' y 'storage_path.*').\"\"\"\n",
    "    cols = df_in.columns\n",
    "    to_drop = []\n",
    "    for p in prefixes:\n",
    "        to_drop.extend([c for c in cols if c == p or c.startswith(p + \".\")])\n",
    "    to_drop = list(dict.fromkeys(to_drop))  # sin duplicados\n",
    "    return df_in.drop(columns=to_drop, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f2033",
   "metadata": {},
   "source": [
    "## üß© Carga de datos (JSON ‚Üí DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4b55701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-16 22:40:32] cargado ‚Üí filas=8032, columnas=64\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(raw)\n",
    "log(f\"cargado ‚Üí filas={df.shape[0]}, columnas={df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ab33c",
   "metadata": {},
   "source": [
    "## ü™ö Limpieza estructural (poda, nulos, constantes, duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88345cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-16 22:40:32] poda por >95% nulos ‚Üí ['is_verified', 'project_id', 'terrain_type', 'bathroom_type', 'construction_permit', 'storage_space_msq', 'favourited_by']\n",
      "[2025-10-16 22:40:32] status eliminado (sin variaci√≥n)\n",
      "[2025-10-16 22:40:32] post-poda ‚Üí filas=8032, columnas=22\n",
      "[2025-10-16 22:40:32] duplicados por id eliminados ‚Üí 178\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Poda t√©cnica + 3.2 columnas espec√≠ficas\n",
    "df = drop_by_prefixes(df, cols_drop_tech)\n",
    "df = df.drop(columns=[c for c in cols_drop_specific if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# 3.3 Columnas con >95% nulos\n",
    "null_ratio = df.isna().mean()\n",
    "high_null_cols = null_ratio[null_ratio > null_col_threshold].index.tolist()\n",
    "if high_null_cols:\n",
    "    df = df.drop(columns=high_null_cols).copy()\n",
    "    log(f\"poda por >{int(null_col_threshold*100)}% nulos ‚Üí {high_null_cols}\")\n",
    "\n",
    "# 3.4 Columnas constantes\n",
    "if \"status\" in df.columns and df[\"status\"].nunique(dropna=False) <= 1:\n",
    "    df = df.drop(columns=[\"status\"]).copy()\n",
    "    log(\"status eliminado (sin variaci√≥n)\")\n",
    "\n",
    "log(f\"post-poda ‚Üí filas={df.shape[0]}, columnas={df.shape[1]}\")\n",
    "\n",
    "# Dedupe por id\n",
    "if \"id\" in df.columns:\n",
    "    dup = int(df.duplicated(subset=[\"id\"], keep=False).sum())\n",
    "    if dup:\n",
    "        df = df.drop_duplicates(subset=[\"id\"]).copy()\n",
    "    log(f\"duplicados por id eliminados ‚Üí {dup}\")\n",
    "else:\n",
    "    log(\"columna 'id' no existe ‚Üí se omite deduplicaci√≥n por id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede7835",
   "metadata": {},
   "source": [
    "## üïí Fechas y m√©tricas derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56d02a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in date_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], utc=True, errors=\"coerce\")\n",
    "\n",
    "now = pd.Timestamp.now(tz=\"UTC\")\n",
    "if \"created_at\" in df.columns:\n",
    "    df[\"days_since_created\"] = (now - df[\"created_at\"]).dt.days\n",
    "    df[\"year_created\"] = df[\"created_at\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34098988",
   "metadata": {},
   "source": [
    "## üí± Conversi√≥n de moneda y correcci√≥n de `price_gtq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea95813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-16 22:40:32] filas eliminadas por currency inv√°lida/no mapeada ‚Üí 19\n",
      "[2025-10-16 22:40:32] price_gtq: rellenadas=642, corregidas_sin_convertir=2\n",
      "[2025-10-16 22:40:32] outliers (>99p) removidos ‚Üí 79 (umbral=25,639,998.67)\n"
     ]
    }
   ],
   "source": [
    "# Asegurar currency\n",
    "if \"currency\" not in df.columns:\n",
    "    df[\"currency\"] = \"GTQ\"\n",
    "\n",
    "df[\"currency\"] = (\n",
    "    df[\"currency\"].astype(str).str.strip().str.upper()\n",
    "      .str.replace(r\"[^A-Z]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "df[\"conversion_rate\"] = df[\"currency\"].map(conversion_rates)\n",
    "\n",
    "mask_bad_curr = df[\"conversion_rate\"].isna()\n",
    "dropped_bad = int(mask_bad_curr.sum())\n",
    "if dropped_bad:\n",
    "    df = df.loc[~mask_bad_curr].copy()\n",
    "    log(f\"filas eliminadas por currency inv√°lida/no mapeada ‚Üí {dropped_bad}\")\n",
    "\n",
    "# Calcular price_gtq si es posible\n",
    "price_num = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "price_gtq_calc = price_num * df[\"conversion_rate\"]\n",
    "\n",
    "if \"price_gtq\" not in df.columns:\n",
    "    df[\"price_gtq\"] = np.nan\n",
    "\n",
    "RTOL, ATOL = 1e-4, 1e-2  # tolerancias para floats\n",
    "pg = df[\"price_gtq\"]\n",
    "\n",
    "mask_fill_missing = (pg.isna() | (pg == 0)) & price_gtq_calc.notna()\n",
    "mask_unconverted = (\n",
    "    (df[\"currency\"] != \"GTQ\")\n",
    "    & pg.notna() & price_num.notna()\n",
    "    & np.isclose(pg, price_num, rtol=RTOL, atol=ATOL)\n",
    "    & price_gtq_calc.notna()\n",
    ")\n",
    "mask_already_ok = (\n",
    "    pg.notna() & price_gtq_calc.notna()\n",
    "    & np.isclose(pg, price_gtq_calc, rtol=RTOL, atol=ATOL)\n",
    ")\n",
    "\n",
    "updates = mask_fill_missing | (mask_unconverted & ~mask_already_ok)\n",
    "df.loc[updates, \"price_gtq\"] = price_gtq_calc[updates]\n",
    "\n",
    "log(f\"price_gtq: rellenadas={int(mask_fill_missing.sum())}, corregidas_sin_convertir={int((mask_unconverted & ~mask_already_ok).sum())}\")\n",
    "\n",
    "# Outliers (p99)\n",
    "if df[\"price_gtq\"].notna().any():\n",
    "    p99 = df[\"price_gtq\"].quantile(outlier_quantile)\n",
    "    n_before = df.shape[0]\n",
    "    df = df[df[\"price_gtq\"] <= p99].copy()\n",
    "    log(f\"outliers (>{int(outlier_quantile*100)}p) removidos ‚Üí {n_before - df.shape[0]} (umbral={p99:,.2f})\")\n",
    "else:\n",
    "    log(\"se omite p99: 'price_gtq' est√° vac√≠o o todo es NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bceb7",
   "metadata": {},
   "source": [
    "## üß© Imputaciones: texto, categ√≥ricas y num√©ricas; m√©trica `price_per_m2` y lat y long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de15fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-16 22:40:32] filas eliminadas sin price_per_m2 ‚Üí 27\n",
      "[diag_geo] lat NA= 0.0 | long NA= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\daher\\Documents\\SEMESTRE10\\ResponsibleAI\\ResponsibleAI-Realworld-Data-Scraper\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Textos\n",
    "for c in [\"title\", \"address\", \"neighborhood\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# Categ√≥ricas\n",
    "if \"property_type\" in df.columns:\n",
    "    df[\"property_type\"] = df[\"property_type\"].fillna(\"unknown\")\n",
    "\n",
    "# Num√©ricas por mediana de property_type (fallback a mediana global si el grupo es chico)\n",
    "for c in [\"bedroom_count\", \"bathroom_count\", \"size_msq\"]:\n",
    "    if c in df.columns:\n",
    "        med_global = df[c].median(skipna=True)\n",
    "        df[c] = df.groupby(\"property_type\")[c].transform(\n",
    "            lambda s: s.fillna(s.median() if s.dropna().size > 2 else med_global)\n",
    "        )\n",
    "\n",
    "# price_per_m2: solo con area v√°lida\n",
    "if {\"size_msq\", \"price_gtq\"}.issubset(df.columns):\n",
    "    df[\"price_per_m2\"] = np.where(\n",
    "        (df[\"size_msq\"] > 0) & df[\"price_gtq\"].notna(),\n",
    "        df[\"price_gtq\"] / df[\"size_msq\"],\n",
    "        np.nan,\n",
    "    )\n",
    "    # criterio: eliminar registros sin price_per_m2 (√°rea inv√°lida/faltante)\n",
    "    before = len(df)\n",
    "    df = df.loc[df[\"price_per_m2\"].notna()].copy()\n",
    "    removed = before - len(df)\n",
    "    if removed:\n",
    "        log(f\"filas eliminadas sin price_per_m2 ‚Üí {removed}\")\n",
    "\n",
    "# lat/long: mediana por ciudad_clean con fallback global\n",
    "for coord in [\"lat\", \"long\"]:\n",
    "    if coord in df.columns:\n",
    "        med_global = df[coord].median(skipna=True)\n",
    "        key = \"city\" if \"city\" in df.columns else \"city\"\n",
    "        df[coord] = df.groupby(key)[coord].transform(\n",
    "            lambda s: s.fillna(s.median() if not np.isnan(s.median()) else med_global)\n",
    "        )\n",
    "\n",
    "# chequeo r√°pido\n",
    "print(\"[diag_geo] lat NA=\", df[\"lat\"].isna().mean() if \"lat\" in df.columns else \"n/a\",\n",
    "      \"| long NA=\", df[\"long\"].isna().mean() if \"long\" in df.columns else \"n/a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5603b",
   "metadata": {},
   "source": [
    "## üßº Limpieza y normalizaci√≥n de texto (city, neighborhood, address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "329c27ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "text_cols = [c for c in [\"city\", \"neighborhood\", \"address\"] if c in df.columns]\n",
    "\n",
    "# 1) Limpieza b√°sica in-place\n",
    "for c in text_cols:\n",
    "    df[c] = df[c].apply(clean_basic)\n",
    "\n",
    "# 2) city ‚Üí normalize_city (usa map con b√∫squeda sin acentos)\n",
    "if \"city\" in df.columns:\n",
    "    df[\"city\"] = df[\"city\"].apply(normalize_city)\n",
    "\n",
    "# 3) CES/CAES/C.A.E.S./Carr... en neighborhood/address (mantiene el resto)\n",
    "for c in [\"neighborhood\", \"address\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].apply(normalize_ces_segment)\n",
    "\n",
    "# 4) Re-limpieza final (por si los reemplazos introdujeron espacios)\n",
    "for c in text_cols:\n",
    "    df[c] = df[c].apply(clean_basic)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cd5cc",
   "metadata": {},
   "source": [
    "## üß≠ Normalizaci√≥n de zonas (neighborhood ‚Üí n√∫mero si aplica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14f11907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNeighborhoods(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Limpia la columna 'neighborhood' dejando solo el n√∫mero de zona si aplica.\n",
    "    Ejemplo:\n",
    "      'Zona 10' -> '10'\n",
    "      'z. 14'   -> '14'\n",
    "      '15'      -> '15'\n",
    "      'Guatemala' -> 'Guatemala'\n",
    "      '' o NaN   -> 'Unknown'\n",
    "    \"\"\"\n",
    "    s2 = s.astype(str).str.strip()\n",
    "    s2 = s2.replace({\"\": np.nan, \"None\": np.nan, \"nan\": np.nan})\n",
    "    s2 = s2.fillna(\"Unknown\")\n",
    "    s2 = s2.str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "    zonePattern = re.compile(r\"\"\"\n",
    "        (?:\n",
    "            \\b(?:z|zona|z\\.)\\s*[-.:]?\\s*   # prefijo opcional\n",
    "        )?\n",
    "        0*(\\d{1,2})\\b                     # n√∫mero de 1‚Äì2 d√≠gitos\n",
    "    \"\"\", re.IGNORECASE | re.VERBOSE)\n",
    "\n",
    "    def normalizeOne(x: str) -> str:\n",
    "        raw = x.strip()\n",
    "        if raw.lower() in {\"\", \"unknown\", \"desconocido\"}:\n",
    "            return \"Unknown\"\n",
    "\n",
    "        # Si es solo n√∫mero\n",
    "        m_num_only = re.fullmatch(r\"0*(\\d{1,2})\", raw)\n",
    "        if m_num_only:\n",
    "            return m_num_only.group(1)\n",
    "\n",
    "        # Si contiene 'zona' o variante\n",
    "        m_zone = zonePattern.search(raw)\n",
    "        if m_zone:\n",
    "            n = int(m_zone.group(1))\n",
    "            if 1 <= n <= 25:  # zonas v√°lidas de Ciudad de Guatemala\n",
    "                return str(n)\n",
    "\n",
    "        # Si no es zona, se deja tal cual\n",
    "        return raw\n",
    "\n",
    "    s3 = s2.apply(normalizeOne)\n",
    "    s3 = s3.str.strip()\n",
    "    return s3\n",
    "\n",
    "if \"neighborhood\" in df.columns:\n",
    "    df[\"neighborhood\"] = cleanNeighborhoods(df[\"neighborhood\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b370390",
   "metadata": {},
   "source": [
    "## üîé Diagn√≥stico r√°pido y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6d67184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[diag] {'rows': 7818, 'cols': 26, 'na_any': '0.0%', 'price_gtq_na': '0.0%', 'size_msq_na': '0.0%', 'lat_na': '0.0%', 'long_na': '0.0%', 'city_levels': 229, 'total_na_cells': 0, 'empty_strings': 748, 'non_finite_nums': 0}\n",
      "id\n",
      "created_at\n",
      "updated_at\n",
      "property_type\n",
      "type\n",
      "address\n",
      "title\n",
      "listed_by_id\n",
      "archived\n",
      "active\n",
      "city\n",
      "neighborhood\n",
      "currency\n",
      "lat\n",
      "long\n",
      "price\n",
      "price_gtq\n",
      "bedroom_count\n",
      "bathroom_count\n",
      "size_msq\n",
      "available_parking_spaces\n",
      "favourite_count\n",
      "days_since_created\n",
      "year_created\n",
      "conversion_rate\n",
      "price_per_m2\n"
     ]
    }
   ],
   "source": [
    "# a) NaN reales\n",
    "total_na = int(df.isna().sum().sum())\n",
    "# b) cadenas vac√≠as en texto\n",
    "empty_strings = 0\n",
    "for c in df.select_dtypes(include=[\"object\", \"string\"]).columns:\n",
    "    empty_strings += int(df[c].astype(str).str.strip().eq(\"\").sum())\n",
    "# c) no finitos en num√©ricos\n",
    "non_finite = 0\n",
    "for c in df.select_dtypes(include=[np.number]).columns:\n",
    "    non_finite += int((~np.isfinite(df[c])).sum())\n",
    "\n",
    "diag = {\n",
    "    \"rows\": df.shape[0],\n",
    "    \"cols\": df.shape[1],\n",
    "    \"na_any\": pct(df.isna().any(axis=1).mean()),\n",
    "    \"price_gtq_na\": pct(df[\"price_gtq\"].isna().mean()) if \"price_gtq\" in df else \"n/a\",\n",
    "    \"size_msq_na\": pct(df[\"size_msq\"].isna().mean()) if \"size_msq\" in df else \"n/a\",\n",
    "    \"lat_na\": pct(df[\"lat\"].isna().mean()) if \"lat\" in df else \"n/a\",\n",
    "    \"long_na\": pct(df[\"long\"].isna().mean()) if \"long\" in df else \"n/a\",\n",
    "    \"city_levels\": df[\"city\"].nunique(dropna=False) if \"city\" in df else \"n/a\",\n",
    "    \"total_na_cells\": total_na,\n",
    "    \"empty_strings\": empty_strings,\n",
    "    \"non_finite_nums\": non_finite,\n",
    "}\n",
    "print(\"[diag]\", diag)\n",
    "\n",
    "# Mostrar nombres de columnas\n",
    "for col in df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061aea2",
   "metadata": {},
   "source": [
    "# üîç Inspecci√≥n individual de columnas (perfilado r√°pido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f9eb66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "=== archived ===\n",
      "dtype: bool\n",
      "missing: 0 (0.00%)\n",
      "\n",
      "[boolean counts]\n",
      " archived\n",
      "False    7818\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "=== listed_by_id ===\n",
      "dtype: object\n",
      "missing: 0 (0.00%)\n",
      "nunique: 105\n",
      "[top categor√≠as] listed_by_id\n",
      "7a893440-988f-4fcc-b8dc-21bc04de33e1    1751\n",
      "e1353d42-be5e-432b-853a-a4083e4ec126     687\n",
      "9169e2fd-4724-4a90-8bdc-3d4fdff72f73     630\n",
      "f88e1b8c-f3c5-432b-99a3-a6687a5a4588     544\n",
      "63e79171-29a1-482a-a0df-29a314b0b357     508\n",
      "585fb986-e360-4894-a21a-aaa31dbfdf82     413\n",
      "98f51467-5a95-4383-9202-41900ff513d2     338\n",
      "1f7004b0-84c6-4394-bf89-3e363f1c6009     337\n",
      "8e46fb29-bca3-44d6-93d4-f004c7950eb6     336\n",
      "c728750e-bfc0-4470-9a6f-ee3d91665e0d     247\n",
      "Name: count, dtype: int64\n",
      "coverage top 10: 74.07%\n",
      "----------------------------------------\n",
      "=== favourite_count ===\n",
      "dtype: int64\n",
      "missing: 0 (0.00%)\n",
      "nunique: 4 (discreta)\n",
      "\n",
      "[value counts]\n",
      " favourite_count\n",
      "0    7580\n",
      "1     217\n",
      "2      13\n",
      "3       8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[describe]\n",
      " count   7,818.00\n",
      "mean        0.03\n",
      "std         0.21\n",
      "min         0.00\n",
      "1%          0.00\n",
      "5%          0.00\n",
      "25%         0.00\n",
      "50%         0.00\n",
      "75%         0.00\n",
      "95%         0.00\n",
      "99%         1.00\n",
      "max         3.00\n",
      "----------------------------------------\n",
      "=== active ===\n",
      "dtype: bool\n",
      "missing: 0 (0.00%)\n",
      "\n",
      "[boolean counts]\n",
      " active\n",
      "True    7818\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = [\"archived\", \"listed_by_id\", \"favourite_count\", \"active\"]\n",
    "quick_profile(df, cols, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b16d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1d0e3349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[diag] {'rows': 7818, 'cols': 22, 'na_any': '0.0%', 'price_gtq_na': '0.0%', 'size_msq_na': '0.0%', 'lat_na': '0.0%', 'long_na': '0.0%', 'city_levels': 229, 'total_na_cells': 0, 'empty_strings': 748, 'non_finite_nums': 0}\n"
     ]
    }
   ],
   "source": [
    "diag = {\n",
    "    \"rows\": df.shape[0],\n",
    "    \"cols\": df.shape[1],\n",
    "    \"na_any\": pct(df.isna().any(axis=1).mean()),\n",
    "    \"price_gtq_na\": pct(df[\"price_gtq\"].isna().mean()) if \"price_gtq\" in df else \"n/a\",\n",
    "    \"size_msq_na\": pct(df[\"size_msq\"].isna().mean()) if \"size_msq\" in df else \"n/a\",\n",
    "    \"lat_na\": pct(df[\"lat\"].isna().mean()) if \"lat\" in df else \"n/a\",\n",
    "    \"long_na\": pct(df[\"long\"].isna().mean()) if \"long\" in df else \"n/a\",\n",
    "    \"city_levels\": df[\"city\"].nunique(dropna=False) if \"city\" in df else \"n/a\",\n",
    "    \"total_na_cells\": total_na,\n",
    "    \"empty_strings\": empty_strings,\n",
    "    \"non_finite_nums\": non_finite,\n",
    "}\n",
    "print(\"[diag]\", diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef6031",
   "metadata": {},
   "source": [
    "## üíæ Exportar dataset limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "629c40a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo exportado: clean_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Exporta a CSV (UTF-8). Si prefieres Parquet, puedes agregar try/except aqu√≠.\n",
    "df.to_csv(\"clean_data.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"‚úÖ Archivo exportado: clean_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
